Directory with transcriptions exists, skipping downloading
patching file data/local/dict_nosp/lexicon0.txt
Prepared input dictionary and phone-sets for Switchboard phase 1.
Switchboard-1 data preparation succeeded.
fix_data_dir.sh: kept all 264333 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/prepare_lang.sh data/local/dict_nosp <unk> data/local/lang_nosp data/lang_nosp
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt
fstaddselfloops data/lang_nosp/phones/wdisambig_phones.int data/lang_nosp/phones/wdisambig_words.int 
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 20 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 168 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 20 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 11 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 46 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 46 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 188 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 93 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 45 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
PPL for SWBD1 trigram LM:
file data/local/lm/heldout: 10000 sentences, 118254 words, 0 OOVs
0 zeroprobs, logprob= -250951 ppl= 90.5055 ppl1= 132.477
PPL for SWBD1 4gram LM:
file data/local/lm/heldout: 10000 sentences, 118254 words, 0 OOVs
0 zeroprobs, logprob= -253745 ppl= 95.1602 ppl1= 139.882
PPL for Fisher 3gram LM:
file data/local/lm/heldout: 10000 sentences, 118254 words, 0 OOVs
0 zeroprobs, logprob= -254817 ppl= 97.0098 ppl1= 142.833
PPL for SWBD1 + Fisher 3gram LM:
file data/local/lm/heldout: 10000 sentences, 118254 words, 0 OOVs
0 zeroprobs, logprob= -245052 ppl= 81.4106 ppl1= 118.102
PPL for Fisher 4gram LM:
file data/local/lm/heldout: 10000 sentences, 118254 words, 0 OOVs
0 zeroprobs, logprob= -258610 ppl= 103.846 ppl1= 153.781
PPL for SWBD1 + Fisher 4gram LM:
file data/local/lm/heldout: 10000 sentences, 118254 words, 0 OOVs
0 zeroprobs, logprob= -248778 ppl= 87.0415 ppl1= 126.986
Converting 'data/local/lm/sw1.o3g.kn.gz' to FST
arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_nosp_sw1_tg/words.txt - data/lang_nosp_sw1_tg/G.fst 
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:94) Reading \data\ section.
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:149) Reading \1-grams: section.
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:149) Reading \2-grams: section.
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:149) Reading \3-grams: section.
LOG (arpa2fst[5.5]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 474982 to 98211
fstisstochastic data/lang_nosp_sw1_tg/G.fst 
-9.23187e-08 -0.589923
Succeeded in formatting LM 'data/local/lm/sw1.o3g.kn.gz' -> 'data/lang_nosp_sw1_tg/G.fst'
arpa-to-const-arpa --bos-symbol=30275 --eos-symbol=30276 --unk-symbol=221 'gunzip -c data/local/lm/sw1_fsh.o4g.kn.gz | utils/map_arpa_lm.pl data/lang_nosp_sw1_fsh_fg/words.txt|' data/lang_nosp_sw1_fsh_fg/G.carpa 
LOG (arpa-to-const-arpa[5.5]:BuildConstArpaLm():const-arpa-lm.cc:1078) Reading gunzip -c data/local/lm/sw1_fsh.o4g.kn.gz | utils/map_arpa_lm.pl data/lang_nosp_sw1_fsh_fg/words.txt|
utils/map_arpa_lm.pl: Processing "\data\"
utils/map_arpa_lm.pl: Processing "\1-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:94) Reading \data\ section.
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \1-grams: section.
utils/map_arpa_lm.pl: Processing "\2-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \2-grams: section.
utils/map_arpa_lm.pl: Processing "\3-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \3-grams: section.
utils/map_arpa_lm.pl: Processing "\4-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \4-grams: section.
Warning: for utterances en_4910-B_013563-013763 and en_4910-B_013594-013790, segments already overlap; leaving these times unchanged.
Warning: for utterances en_4910-B_025539-025791 and en_4910-B_025541-025674, segments already overlap; leaving these times unchanged.
Warning: for utterances en_4910-B_032263-032658 and en_4910-B_032299-032406, segments already overlap; leaving these times unchanged.
Warning: for utterances en_4910-B_035678-035757 and en_4910-B_035715-035865, segments already overlap; leaving these times unchanged.
Data preparation and formatting completed for Eval 2000
(but not MFCC extraction)
fix_data_dir.sh: kept 4458 utterances out of 4466
fix_data_dir.sh: old files are kept in data/eval2000/.backup
Data preparation and formatting completed for RT-03
(but not MFCC extraction)
steps/make_mfcc.sh --nj 50 --cmd run.pl data/train exp/make_mfcc/train mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: It seems not all of the feature files were successfully procesed (264151 != 264333); consider using utils/fix_data_dir.sh data/train
steps/make_mfcc.sh: Succeeded creating MFCC features for train
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept 264151 utterances out of 264333
fix_data_dir.sh: old files are kept in data/train/.backup
steps/make_mfcc.sh --nj 50 --cmd run.pl data/eval2000 exp/make_mfcc/eval2000 mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/eval2000
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for eval2000
steps/compute_cmvn_stats.sh data/eval2000 exp/make_mfcc/eval2000 mfcc
Succeeded creating CMVN stats for eval2000
fix_data_dir.sh: kept all 4458 utterances.
fix_data_dir.sh: old files are kept in data/eval2000/.backup
steps/make_mfcc.sh --nj 50 --cmd run.pl data/rt03 exp/make_mfcc/rt03 mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/rt03
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for rt03
steps/compute_cmvn_stats.sh data/rt03 exp/make_mfcc/rt03 mfcc
Succeeded creating CMVN stats for rt03
fix_data_dir.sh: kept all 8422 utterances.
fix_data_dir.sh: old files are kept in data/rt03/.backup
utils/subset_data_dir.sh: reducing #utt from 264151 to 4000
utils/subset_data_dir.sh: reducing #utt from 264151 to 260151
feat-to-len scp:data/train_nodev/feats.scp ark,t:data/train_100kshort/tmp.len 
utils/subset_data_dir.sh: reducing #utt from 260151 to 100000
utils/subset_data_dir.sh: reducing #utt from 100000 to 30000
utils/subset_data_dir.sh: reducing #utt from 260151 to 100000
Reduced number of utterances from 100000 to 76688
Using fix_data_dir.sh to reconcile the other files.
fix_data_dir.sh: kept 76688 utterances out of 100000
fix_data_dir.sh: old files are kept in data/train_100k_nodup/.backup
Reduced number of utterances from 260151 to 192871
Using fix_data_dir.sh to reconcile the other files.
fix_data_dir.sh: kept 192871 utterances out of 260151
fix_data_dir.sh: old files are kept in data/train_nodup/.backup
steps/train_mono.sh --nj 30 --cmd run.pl data/train_30kshort data/lang_nosp exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
22 warnings in exp/mono/log/update.*.log
16 warnings in exp/mono/log/acc.*.*.log
6988 warnings in exp/mono/log/align.*.*.log
exp/mono: nj=30 align prob=-94.82 over 11.78h [retry=0.5%, fail=0.0%] states=146 gauss=988
steps/train_mono.sh: Done training monophone system in exp/mono
steps/align_si.sh --nj 30 --cmd run.pl data/train_100k_nodup data/lang_nosp exp/mono exp/mono_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_100k_nodup using model from exp/mono, putting alignments in exp/mono_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono_ali
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --cmd run.pl 3200 30000 data/train_100k_nodup data/lang_nosp exp/mono_ali exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
8550 warnings in exp/tri1/log/align.*.*.log
3688 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/build_tree.log
exp/tri1: nj=30 align prob=-96.44 over 109.30h [retry=3.6%, fail=0.1%] states=2360 gauss=30085 tree-impr=3.01
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
steps/align_si.sh --nj 30 --cmd run.pl data/train_100k_nodup data/lang_nosp exp/tri1 exp/tri1_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_100k_nodup using model from exp/tri1, putting alignments in exp/tri1_ali
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1_ali
steps/decode_si.sh --nj 30 --cmd run.pl --mem 4G --config conf/decode.config exp/tri1/graph_nosp_sw1_tg data/eval2000 exp/tri1/decode_eval2000_nosp_sw1_tg
decode.sh: feature type is delta
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --cmd run.pl 4000 70000 data/train_100k_nodup data/lang_nosp exp/tri1_ali exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2/log/analyze_alignments.log
4393 warnings in exp/tri2/log/acc.*.*.log
9330 warnings in exp/tri2/log/align.*.*.log
1 warnings in exp/tri2/log/build_tree.log
exp/tri2: nj=30 align prob=-95.60 over 109.29h [retry=3.3%, fail=0.2%] states=2928 gauss=70119 tree-impr=3.72
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
steps/align_si.sh --nj 30 --cmd run.pl data/train_100k_nodup data/lang_nosp exp/tri2 exp/tri2_ali_100k_nodup
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_100k_nodup using model from exp/tri2, putting alignments in exp/tri2_ali_100k_nodup
steps/decode.sh --nj 30 --cmd run.pl --mem 4G --config conf/decode.config exp/tri2/graph_nosp_sw1_tg data/eval2000 exp/tri2/decode_eval2000_nosp_sw1_tg
decode.sh: feature type is delta
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri1/graph_nosp_sw1_tg exp/tri1/decode_eval2000_nosp_sw1_tg
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_eval2000_nosp_sw1_tg/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(2,16,94) and mean=36.8
steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_eval2000_nosp_sw1_tg/log/analyze_lattice_depth_stats.log
data/eval2000/stm exists: using local/score_sclite.sh
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2_ali_100k_nodup
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2_ali_100k_nodup/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
steps/align_si.sh --nj 30 --cmd run.pl data/train_nodup data/lang_nosp exp/tri2 exp/tri2_ali_nodup
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_nodup using model from exp/tri2, putting alignments in exp/tri2_ali_nodup
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2_ali_nodup
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2_ali_nodup/log/analyze_alignments.log
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --cmd run.pl 6000 140000 data/train_nodup data/lang_nosp exp/tri2_ali_nodup exp/tri3
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
steps/train_lda_mllt.sh: Converting alignments from exp/tri2_ali_nodup to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri2/graph_nosp_sw1_tg exp/tri2/decode_eval2000_nosp_sw1_tg
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2/decode_eval2000_nosp_sw1_tg/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(2,13,84) and mean=32.8
steps/diagnostic/analyze_lats.sh: see stats in exp/tri2/decode_eval2000_nosp_sw1_tg/log/analyze_lattice_depth_stats.log
data/eval2000/stm exists: using local/score_sclite.sh
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri3
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3/log/analyze_alignments.log
8366 warnings in exp/tri3/log/acc.*.*.log
1 warnings in exp/tri3/log/build_tree.log
209 warnings in exp/tri3/log/lda_acc.*.log
22218 warnings in exp/tri3/log/align.*.*.log
exp/tri3: nj=30 align prob=-49.60 over 284.66h [retry=3.1%, fail=0.1%] states=4600 gauss=140244 tree-impr=3.54 lda-sum=13.00 mllt:impr,logdet=1.02,1.87
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri3
steps/get_prons.sh --cmd run.pl data/train_nodup data/lang_nosp exp/tri3
steps/get_prons.sh: exp/tri3/ali.1.gz exists, so starting from alignments.
steps/get_prons.sh: done writing prons to exp/tri3/prons.*.gz, silence counts in 
steps/get_prons.sh: exp/tri3/sil_counts_nowb.txt and pronunciation counts in 
steps/get_prons.sh: exp/tri3/pron_counts.{int,txt}
steps/get_prons.sh: ... and also in exp/tri3/pron_counts_nowb.txt
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.
utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in data/local/dict/
utils/dict_dir_add_pronprobs.sh: validating data/local/dict ..
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

Some low-probability prons include: 
# sort -k2,2 -n data/local/dict/lexiconp.txt  | head -n 8
let 0.00459981 v ae l ey
become 0.006734 b ah k ah m
e- 0.00869567 eh m ih n ih n t l iy
s- 0.00909091 s p ow r t s
w- 0.00970873 w er s t
re- 0.00980391 r eh l ax t ih v l iy
a- 0.0110701 ae l
minute 0.0136363 m ay n uw t
utils/prepare_lang.sh data/local/dict <unk> data/local/lang data/lang
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

fstaddselfloops data/lang/phones/wdisambig_phones.int data/lang/phones/wdisambig_words.int 
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 168 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 11 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 46 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 46 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 188 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 89 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 64 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
Converting 'data/local/lm/sw1.o3g.kn.gz' to FST
arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_sw1_tg/words.txt - data/lang_sw1_tg/G.fst 
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:94) Reading \data\ section.
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:149) Reading \1-grams: section.
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:149) Reading \2-grams: section.
LOG (arpa2fst[5.5]:Read():arpa-file-parser.cc:149) Reading \3-grams: section.
LOG (arpa2fst[5.5]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 474982 to 98211
fstisstochastic data/lang_sw1_tg/G.fst 
-9.23187e-08 -0.589923
Succeeded in formatting LM 'data/local/lm/sw1.o3g.kn.gz' -> 'data/lang_sw1_tg/G.fst'
arpa-to-const-arpa --bos-symbol=30275 --eos-symbol=30276 --unk-symbol=221 'gunzip -c data/local/lm/sw1_fsh.o4g.kn.gz | utils/map_arpa_lm.pl data/lang_sw1_fsh_fg/words.txt|' data/lang_sw1_fsh_fg/G.carpa 
LOG (arpa-to-const-arpa[5.5]:BuildConstArpaLm():const-arpa-lm.cc:1078) Reading gunzip -c data/local/lm/sw1_fsh.o4g.kn.gz | utils/map_arpa_lm.pl data/lang_sw1_fsh_fg/words.txt|
utils/map_arpa_lm.pl: Processing "\data\"
utils/map_arpa_lm.pl: Processing "\1-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:94) Reading \data\ section.
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \1-grams: section.
utils/map_arpa_lm.pl: Processing "\2-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \2-grams: section.
steps/decode.sh --nj 30 --cmd run.pl --mem 4G --config conf/decode.config exp/tri3/graph_nosp_sw1_tg data/eval2000 exp/tri3/decode_eval2000_nosp_sw1_tg
decode.sh: feature type is lda
utils/map_arpa_lm.pl: Processing "\3-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \3-grams: section.
utils/map_arpa_lm.pl: Processing "\4-grams:\"
LOG (arpa-to-const-arpa[5.5]:Read():arpa-file-parser.cc:149) Reading \4-grams: section.
steps/align_fmllr.sh --nj 30 --cmd run.pl data/train_nodup data/lang exp/tri3 exp/tri3_ali_nodup
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_nodup using exp/tri3/final.mdl and speaker-independent features.
steps/decode.sh --nj 30 --cmd run.pl --mem 4G --config conf/decode.config exp/tri3/graph_sw1_tg data/eval2000 exp/tri3/decode_eval2000_sw1_tg
decode.sh: feature type is lda
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri3_ali_nodup
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3_ali_nodup/log/analyze_alignments.log
5056 warnings in exp/tri3_ali_nodup/log/align_pass1.*.log
220 warnings in exp/tri3_ali_nodup/log/fmllr.*.log
4812 warnings in exp/tri3_ali_nodup/log/align_pass2.*.log
steps/train_sat.sh --cmd run.pl 11500 200000 data/train_nodup data/lang exp/tri3_ali_nodup exp/tri4
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: Using transforms from exp/tri3_ali_nodup
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3/graph_sw1_tg exp/tri3/decode_eval2000_sw1_tg
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3/decode_eval2000_sw1_tg/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,7,45) and mean=17.9
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3/decode_eval2000_sw1_tg/log/analyze_lattice_depth_stats.log
data/eval2000/stm exists: using local/score_sclite.sh
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3/graph_nosp_sw1_tg exp/tri3/decode_eval2000_nosp_sw1_tg
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3/decode_eval2000_nosp_sw1_tg/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,8,51) and mean=20.1
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3/decode_eval2000_nosp_sw1_tg/log/analyze_lattice_depth_stats.log
data/eval2000/stm exists: using local/score_sclite.sh
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri3_ali_nodup to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
run.pl: 30 / 30 failed, log is in exp/tri4/log/fmllr.4.*.log
steps/align_fmllr.sh --nj 30 --cmd run.pl data/train_nodup data/lang exp/tri3 exp/tri3_ali_nodup
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_nodup using exp/tri3/final.mdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri3_ali_nodup
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3_ali_nodup/log/analyze_alignments.log
4812 warnings in exp/tri3_ali_nodup/log/align_pass2.*.log
220 warnings in exp/tri3_ali_nodup/log/fmllr.*.log
5056 warnings in exp/tri3_ali_nodup/log/align_pass1.*.log
steps/train_sat.sh --cmd run.pl 11500 200000 data/train_nodup data/lang exp/tri3_ali_nodup exp/tri4
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: Using transforms from exp/tri3_ali_nodup
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri3_ali_nodup to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri4
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri4/log/analyze_alignments.log
19026 warnings in exp/tri4/log/align.*.*.log
1 warnings in exp/tri4/log/build_tree.log
9092 warnings in exp/tri4/log/acc.*.*.log
918 warnings in exp/tri4/log/fmllr.*.*.log
steps/train_sat.sh: Likelihood evolution:
-51.8392 -51.268 -51.0632 -50.8545 -50.0823 -49.355 -48.8716 -48.5042 -48.2293 -47.7193 -47.5306 -47.2829 -47.1559 -47.0577 -46.9692 -46.8883 -46.8141 -46.7467 -46.6846 -46.5426 -46.4618 -46.4125 -46.3693 -46.329 -46.2908 -46.2541 -46.2187 -46.1847 -46.1521 -46.0784 -46.0293 -46.0048 -45.9887 -45.9774 
exp/tri4: nj=30 align prob=-49.72 over 284.62h [retry=2.4%, fail=0.1%] states=8920 gauss=200270 fmllr-impr=1.18 over 207.33h tree-impr=5.90
steps/train_sat.sh: done training SAT system in exp/tri4
run.sh: exiting early since --train-discriminative is false.
steps/decode_fmllr.sh --nj 30 --cmd run.pl --mem 4G --config conf/decode.config exp/tri4/graph_sw1_tg data/eval2000 exp/tri4/decode_eval2000_sw1_tg
steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 30 --cmd run.pl --mem 4G --beam 8.0 --model exp/tri4/final.alimdl --max-active 2000 exp/tri4/graph_sw1_tg data/eval2000 exp/tri4/decode_eval2000_sw1_tg.si
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg exp/tri4/decode_eval2000_sw1_tg.si
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_eval2000_sw1_tg.si/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,18) and mean=7.8
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_eval2000_sw1_tg.si/log/analyze_lattice_depth_stats.log
data/eval2000/stm exists: using local/score_sclite.sh
steps/decode_fmllr.sh: feature type is lda
steps/decode_fmllr.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr.sh: doing main lattice generation phase
steps/decode_fmllr.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg exp/tri4/decode_eval2000_sw1_tg
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_eval2000_sw1_tg/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,23) and mean=9.8
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_eval2000_sw1_tg/log/analyze_lattice_depth_stats.log
data/eval2000/stm exists: using local/score_sclite.sh
steps/decode_fmllr.sh --nj 30 --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg data/train_dev exp/tri4/decode_dev_sw1_tg
steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 30 --cmd run.pl --mem 4G --beam 10.0 --model exp/tri4/final.alimdl --max-active 2000 exp/tri4/graph_sw1_tg data/train_dev exp/tri4/decode_dev_sw1_tg.si
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg exp/tri4/decode_dev_sw1_tg.si
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_dev_sw1_tg.si/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,5,27) and mean=11.3
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_dev_sw1_tg.si/log/analyze_lattice_depth_stats.log
data/train_dev/stm does not exist: using local/score_basic.sh
steps/decode_fmllr.sh: feature type is lda
steps/decode_fmllr.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr.sh: doing main lattice generation phase
steps/decode_fmllr.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg exp/tri4/decode_dev_sw1_tg
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_dev_sw1_tg/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,5,28) and mean=11.5
steps/diagnostic/analyze_lats.sh: see stats in exp/tri4/decode_dev_sw1_tg/log/analyze_lattice_depth_stats.log
data/train_dev/stm does not exist: using local/score_basic.sh
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_sw1_tg data/lang_sw1_fsh_fg data/eval2000 exp/tri4/decode_eval2000_sw1_tg exp/tri4/decode_eval2000_sw1_fsh_fg
data/eval2000/stm exists: using local/score_sclite.sh
